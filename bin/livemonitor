#!/bin/bash
# Basic webserver monitoring tool
# Monitors if there are any new webservers that returns TTP 200 OK
# * Requires httpx
#
# Usage:
# livemonitor mytarget
#
# Extended usage: set this as an daily cron task

TARGET=$1
RECON_DIR="$HOME/recon"
TARGET_DIR="$RECON_DIR/$TARGET"

echo "Probing $TARGET..."

MONITOR_BASE_DIR="$TARGET_DIR/.livemonitor"
if [ ! -d $MONITOR_BASE_DIR ]; then
    mkdir $MONITOR_BASE_DIR 
fi;

DIFF_LIVE="$MONITOR_BASE_DIR/live.diff"
NEW_LIVE="$MONITOR_BASE_DIR/live.new"
KNOWN_LIVE="$MONITOR_BASE_DIR/live.known"

/root/go/bin/httpx -l "$TARGET_DIR/subdomains.txt" -silent -mc 200 | tee $NEW_LIVE

if [ -f $NEW_LIVE ]; then
	cat $NEW_LIVE | anew $KNOWN_LIVE > $DIFF_LIVE
	if [ -s $DIFF_LIVE ]; then
		now=$(date +%Y-%m-%d_%R)
		TIMESTAMPED_DIFF_FILE="$MONITOR_BASE_DIR/$now.diff"
		cp $DIFF_LIVE $TIMESTAMPED_DIFF_FILE
		echo "New live webservers detected in $TARGET "'```'$TIMESTAMPED_DIFF_FILE'```' | notify -silent -id livemonitor
		
		# If 20 or fewer results, also send the list of new websites
		NUM_NEW=$(wc -l < $DIFF_LIVE)
		if [ $NUM_NEW -le 20 ]; then
			echo "```$(cat $DIFF_LIVE)```" | notify -silent -id livemonitor
		fi
		
		# Run keyword_hunter.py on each new live website
		echo "Running keyword hunter on new live websites..."
		while IFS= read -r url; do
			echo "Hunting keywords in: $url"
			/root/.pyenv/shims/python3 "$HOME/tools/bb-scripts/scripts/keyword_hunter/keyword_hunter.py" -u "$url" -c "$HOME/tools/bb-scripts/scripts/keyword_hunter/config.yaml"
		done < $DIFF_LIVE
		
		# Run webpage_analyzer.py on each new live website
		echo "Running webpage analyzer on new live websites..."
		while IFS= read -r url; do
			echo "Analyzing webpage: $url"
			/root/.pyenv/shims/python3 "$HOME/tools/bb-scripts/scripts/webpage_analyzer/webpage_analyzer.py" -u "$url" -c "$HOME/tools/bb-scripts/scripts/webpage_analyzer/config.yaml"
		done < $DIFF_LIVE
	fi;
	else
	cp $NEW_LIVE $KNOWN_LIVE
fi;
